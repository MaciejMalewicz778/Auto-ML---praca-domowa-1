{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# skopt\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "#helpers\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "df_1 = fetch_openml(data_id=31)\n",
    "df_2 = fetch_openml(data_id=1489)\n",
    "df_3 = fetch_openml(data_id=1558)\n",
    "df_4 = fetch_openml(data_id=18)\n",
    "\n",
    "X_1 = df_1.data\n",
    "y_1 = df_1.target\n",
    "Xs.append(X_1)\n",
    "ys.append(y_1)\n",
    "\n",
    "X_2 = df_2.data\n",
    "y_2 = df_2.target\n",
    "Xs.append(X_2)\n",
    "ys.append(y_2)\n",
    "\n",
    "X_3 = df_3.data\n",
    "y_3 = df_3.target\n",
    "Xs.append(X_3)\n",
    "ys.append(y_3)\n",
    "\n",
    "X_4 = df_3.data\n",
    "y_4 = df_3.target\n",
    "Xs.append(X_4)\n",
    "ys.append(y_4)\n",
    "\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets into train and test\n",
    "X_train_arr = []\n",
    "X_test_arr = []\n",
    "y_train_arr = []\n",
    "y_test_arr = []\n",
    "cols_num = []\n",
    "cols_cat = []\n",
    "\n",
    "for i in range(len(Xs)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs[i], ys[i], test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "    X_train_arr.append(X_train)\n",
    "    X_test_arr.append(X_test)\n",
    "    y_train_arr.append(y_train)\n",
    "    y_test_arr.append(y_test)\n",
    "\n",
    "    numeric_features = X_train_arr[i].select_dtypes(exclude=['category']).columns\n",
    "    categorical_features = X_train_arr[i].select_dtypes(include=['category']).columns\n",
    "\n",
    "    cols_num.append(numeric_features)\n",
    "    cols_cat.append(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to wrap model and do imputing and encoding\n",
    "\n",
    "def getPipeline(model, num_cols, cat_cols):\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    "    )\n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]\n",
    "    )\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, num_cols),\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)]\n",
    "    )\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_log_reg = {\n",
    "    'classifier__C': np.logspace(-4, 4, 50),\n",
    "    'classifier__l1_ratio': np.linspace(0, 1, 50)\n",
    "}\n",
    "\n",
    "grid_tree = {\n",
    "    'classifier__max_depth': np.concatenate(([None], range(5, 100, 5))),\n",
    "    'classifier__min_samples_split': range(1, 10),\n",
    "    'min_samples_leaf': range(2, 50, 2),\n",
    "    'max_leaf_nodes': np.concatenate(([None], range(30, 330, 30))),\n",
    "    'ccp_alpha': np.logspace(-3, 3, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important helpers. They Return best CV scores and params for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomCVResults(model, grid, n_iter=10, n_jobs=1, verbose=0):\n",
    "    search_res = []\n",
    "    for i in range(len(X_train_arr)):\n",
    "        clf = getPipeline(model, cols_num[i], cols_cat[i])\n",
    "\n",
    "        res = RandomizedSearchCV(clf, param_distributions=grid, random_state=RANDOM_STATE, cv=cv, scoring='accuracy', n_iter=n_iter, n_jobs=n_jobs, verbose=verbose)\n",
    "        res.fit(X_train_arr[i], y_train_arr[i])\n",
    "\n",
    "        search_res.append(res)\n",
    "    \n",
    "    return search_res\n",
    "\n",
    "def getBayesCVResults(model, grid, n_iter=10, n_jobs=1, verbose=0):\n",
    "    search_res = []\n",
    "    for i in range(len(X_train_arr)):\n",
    "        clf = getPipeline(model, cols_num[i], cols_cat[i])\n",
    "\n",
    "        res = BayesSearchCV(clf, search_spaces=grid, random_state=RANDOM_STATE, cv=cv, scoring='accuracy', n_iter=n_iter, n_jobs=n_jobs, verbose=verbose)\n",
    "        res.fit(X_train_arr[i], y_train_arr[i])\n",
    "        search_res.append(res)\n",
    "        print(f\"Fit for set number {i} is done\")\n",
    "    \n",
    "    return search_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for best hyperparams (Random search method) for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr = LogisticRegression(penalty='elasticnet', solver='saga', random_state=RANDOM_STATE, max_iter=1000)\n",
    "search_rand_lr = getRandomCVResults(lr, grid_log_reg, 50, -1)\n",
    "\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__l1_ratio': 0.7346938775510203, 'classifier__C': 4714.8663634573895}\n",
      "0.7142857142857143\n",
      "\n",
      "\n",
      "{'classifier__l1_ratio': 0.9795918367346939, 'classifier__C': 1.2067926406393288}\n",
      "0.7525106064736182\n",
      "\n",
      "\n",
      "{'classifier__l1_ratio': 0.7346938775510203, 'classifier__C': 4714.8663634573895}\n",
      "0.8808471813946047\n",
      "\n",
      "\n",
      "{'classifier__l1_ratio': 0.7346938775510203, 'classifier__C': 4714.8663634573895}\n",
      "0.8808471813946047\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in search_rand_lr:\n",
    "    print(el.best_params_)\n",
    "    print(el.best_score_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for optimal, default hyperparamer dictionary (for Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0.7346938775510203, 'C': 4714.8663634573895}\n",
      "{'l1_ratio': 0.9795918367346939, 'C': 1.2067926406393288}\n",
      "{'l1_ratio': 0.7346938775510203, 'C': 4714.8663634573895}\n",
      "{'l1_ratio': 0.7346938775510203, 'C': 4714.8663634573895}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "hyper_params_scores = []\n",
    "for search_res_idx in range(len(search_rand_lr)):\n",
    "    params = helpers.decodeParams(search_rand_lr[search_res_idx].best_params_)\n",
    "    scores = []\n",
    "    print(params)\n",
    "    for i in range(len(X_train_arr)):\n",
    "        model = getPipeline(LogisticRegression(penalty='elasticnet', max_iter=1000, random_state=RANDOM_STATE, solver='saga', **params), cols_num[i], cols_cat[i])\n",
    "        score = cross_val_score(model, X_train_arr[i], y_train_arr[i], cv=cv)\n",
    "        scores.append(np.mean(score))\n",
    "    \n",
    "\n",
    "    hyper_params_scores.append(scores)\n",
    "\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify whether it is real that different hyperparams gives the same score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71428571 0.71428571 0.71428571 0.71428571 0.71428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71428571 0.71428571 0.71428571 0.71428571 0.71428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = getPipeline(LogisticRegression(penalty='elasticnet', max_iter=1000, random_state=RANDOM_STATE, solver='saga', l1_ratio=0.735, C=4714.9), cols_num[0], cols_cat[0])\n",
    "print(cross_val_score(model, X_train_arr[0], y_train_arr[0], cv=cv))\n",
    "\n",
    "model = getPipeline(LogisticRegression(penalty='elasticnet', max_iter=1000, random_state=RANDOM_STATE, solver='saga', l1_ratio=0.98, C=1.207), cols_num[0], cols_cat[0])\n",
    "print(cross_val_score(model, X_train_arr[0], y_train_arr[0], cv=cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.807056533320998, 0.8071226708871355, 0.807056533320998, 0.807056533320998]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.mean(scores) for scores in hyper_params_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for best hyperparams (Bayesian method) for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit for set number 0 is done\n",
      "Fit for set number 1 is done\n",
      "Fit for set number 2 is done\n",
      "Fit for set number 3 is done\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr = LogisticRegression(penalty='elasticnet', solver='saga', random_state=RANDOM_STATE, max_iter=1000)\n",
    "search_bayes_lr = getBayesCVResults(lr, grid_log_reg, 50, -1)\n",
    "\n",
    "warnings.filterwarnings('default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "OrderedDict([('classifier__C', 719.6856730011514), ('classifier__l1_ratio', 0.36734693877551017)])\n",
      "0.7142857142857143\n",
      "{'classifier__l1_ratio': 0.7346938775510203, 'classifier__C': 4714.8663634573895}\n",
      "**********\n",
      "0.7525106064736182\n",
      "OrderedDict([('classifier__C', 0.8286427728546842), ('classifier__l1_ratio', 0.5714285714285714)])\n",
      "0.7525106064736182\n",
      "{'classifier__l1_ratio': 0.9795918367346939, 'classifier__C': 1.2067926406393288}\n",
      "**********\n",
      "0.8808471813946047\n",
      "OrderedDict([('classifier__C', 719.6856730011514), ('classifier__l1_ratio', 0.36734693877551017)])\n",
      "0.8808471813946047\n",
      "{'classifier__l1_ratio': 0.7346938775510203, 'classifier__C': 4714.8663634573895}\n",
      "**********\n",
      "0.8808471813946047\n",
      "OrderedDict([('classifier__C', 719.6856730011514), ('classifier__l1_ratio', 0.36734693877551017)])\n",
      "0.8808471813946047\n",
      "{'classifier__l1_ratio': 0.7346938775510203, 'classifier__C': 4714.8663634573895}\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(search_bayes_lr[i].best_score_)\n",
    "    print(search_bayes_lr[i].best_params_)\n",
    "    print(search_rand_lr[i].best_score_)\n",
    "    print(search_rand_lr[i].best_params_)\n",
    "    print(10*'*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
